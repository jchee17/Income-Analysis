{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load workbook_2.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "# In[96]:\n",
      "\n",
      "# comparison of multiple classifiers on adult dataset\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import timeit\n",
      "from sklearn import preprocessing\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn import linear_model, neighbors\n",
      "from sklearn.svm import SVC\n",
      "from sklearn import metrics\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "import matplotlib.pyplot as plt\n",
      "from ggplot import *\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "adult = pd.read_csv('adult.txt', names=['age','workclass','fnlwgt','education','education-num','marital-status',\n",
      "                                       'occupation','relationship','race','sex','capital-gain','captial-loss',\n",
      "                                       'hours-per-week','native-country','income'])\n",
      "\n",
      "\n",
      "# In[2]:\n",
      "\n",
      "adult.head()\n",
      "\n",
      "\n",
      "# In[ ]:\n",
      "\n",
      "# first, some outlier investigation\n",
      "# one-class SVM as outlier detection in high-dimension, without any assumption on distribution of inlying data\n",
      "# for a later time\n",
      "\n",
      "\n",
      "# In[10]:\n",
      "\n",
      "# preprocessing, dealing with categorical variables\n",
      "X = adult.drop('income', axis=1)\n",
      "X = pd.get_dummies(X)\n",
      "y = adult['income']\n",
      "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2)\n",
      "print(train_X.shape, test_X.shape)\n",
      "\n",
      "\n",
      "# In[ ]:\n",
      "\n",
      "sample = adult.sample(frac=0.1)\n",
      "\n",
      "\n",
      "# In[74]:\n",
      "\n",
      "# logistic Regression\n",
      "logreg = linear_model.LogisticRegression()\n",
      "start = timeit.default_timer()\n",
      "logreg = logreg.fit(train_X, train_y)\n",
      "print(timeit.default_timer()-start)\n",
      "logreg.score(test_X, test_y)\n",
      "\n",
      "\n",
      "# In[4]:\n",
      "\n",
      "# SVM\n",
      "# to computationally difficult on laptop\n",
      "clf = SVC(kernel='linear')\n",
      "clf = clf.fit(train_X.sample(frac=0.1), train_y.sample(frac=0.1))\n",
      "\n",
      "\n",
      "# In[95]:\n",
      "\n",
      "# Stochastic Gradient Descent\n",
      "sgd = linear_model.SGDClassifier(loss='hinge', penalty='l2', shuffle=True)\n",
      "start = timeit.default_timer()\n",
      "sgd = sgd.fit(train_X, train_y)\n",
      "print(timeit.default_timer()-start)\n",
      "sgd.score(test_X, test_y)\n",
      "\n",
      "\n",
      "# In[102]:\n",
      "\n",
      "# nearest-neighbors classifier\n",
      "knn = neighbors.KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
      "knn = knn.fit(train_X, train_y)\n",
      "knn.score(test_X, test_y)\n",
      "\n",
      "\n",
      "# In[ ]:\n",
      "\n",
      "# random forest classifier\n",
      "rfc\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}